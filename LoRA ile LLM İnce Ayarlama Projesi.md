# LoRA ile LLM Ä°nce Ayarlama Projesi

Bu repository (kod deposu), bÃ¼yÃ¼k dil modellerini (LLM - Large Language Model) LoRA (Low-Rank Adaptation) tekniÄŸini kullanarak verimli bir ÅŸekilde ince ayarlamak iÃ§in gerekli kodlarÄ± iÃ§erir.

## ğŸš€ Ã–zellikler

- [LLaMA-2 7B](https://huggingface.co/meta-llama/Llama-2-7b-hf) modelini LoRA ile ince ayarlama
- DÃ¼ÅŸÃ¼k bellek kullanÄ±mÄ± sayesinde tÃ¼ketici sÄ±nÄ±fÄ± GPU'larda Ã§alÄ±ÅŸabilme
- Ã–zel veri setleriyle hÄ±zlÄ± adaptasyon

## ğŸ“‹ Gereksinimler

- Python 3.8+
- PyTorch 2.0+
- Transformers 4.30+
- PEFT 0.4+
- Datasets 2.12+

## ğŸ”§ Kurulum

```bash
# Sanal ortam oluÅŸturun (isteÄŸe baÄŸlÄ±)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# veya
venv\Scripts\activate  # Windows

# Gerekli paketleri yÃ¼kleyin
pip install torch transformers peft datasets
